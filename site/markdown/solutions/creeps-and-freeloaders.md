---
title: Improving Women's Safety and Filtering Out Freeloaders
---

Three key safety features will be built into the platform: accountability, informed choice, and education. Actively policing members leads to all kinds of issues and isn't scalable. Rather, we will empower the community to moderate itself.

We cannot prevent bad users from joining the platform, but what we can do is hold everyone accountable for their actions. In the cases where there are sexually predatory users, hosts who make inappropriate sexual advances on their guests, or people who send creepy messages; if those people make members feel uncomfortable or unsafe, they should be made accountable for that by in some way having that information reflected in their public record.

Theoretically, this is already a feature of CouchSurfing in the form of negative references. However negative references are so [stigmatised and unused](/issues/reviews) that they are not effective. Most users have 100% positive references, and so it is [too hard to tell whether an experience with anyone will be safe](/issues/creeps-and-freeloaders).

By [redesigning the review system](/solutions/reviews), we make users more likely to leave negative reviews. Member's score will mostly fall in the 60-80% range, which will make leaving negative reviews less of a punishment. Providing a couple more questions will also leave more nuanced answers than a simple positive/negative. For instance, there may be situations where a host makes sexual suggestions to their guest who brushes it off but is made to feel uncomfortable. That guest may say overall they would still stay with that host, while still signalling that discomfort. The set of questions is now a bit broader while still being simple. Users can leave these reviews anonymously and also be prompted for a public reference that is not attached to a positive or negative rating. Great members who people feel safe around and have a good time with will be reflected with having high scores.

Given that a member's score now accurately reflects their actions and holds them accountable, people can make informed choices. Everyone has different tolerances for what makes them uncomfortable or makes them feel unsafe, and so everyone can choose individually what members they choose to interact with by filtering by their score. Further, there will be the ability to filter by sub-community. For instance, women may want to see the community standing of a male host just amongst other female surfers. This way, predatory hosts can be filtered out of the community.

There will still need to be [moderators](/governance) to deal with cases such as explicit harassment and assault. To prevent these kind of users from reentering the platform by creating a new account, we have introduced a better [verification system](/solutions/communities-and-trust).

Similarly, if you receive a creepy message, you will be able to flag it which will reduce the users' score. You may filter messages able to be sent to you by score, eliminating creeps from your inbox.

Education will be important and we are exploring how this will be implemented. The key messages to prominently get across is that the platform is not a dating or hook-up app and that people should be aware of the vulnerabilities and power imbalances that are created when people stay in each others' homes. This may take the form of messages that appear when signing up or displaying messages throughout the app. 

Similarly, if users join just for free accommodation and take advantage of hosts' hospitality without properly engaging, this will be reflected on their score so they may be filtered out if they repeatedly act that way.

